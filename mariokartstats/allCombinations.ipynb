{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.12/site-packages (4.13.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in ./.venv/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (5.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas openpyxl lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3952/4130451171.py:136: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(str(table))\n",
      "/tmp/ipykernel_3952/4130451171.py:136: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(str(table))\n",
      "/tmp/ipykernel_3952/4130451171.py:136: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(str(table))\n",
      "/tmp/ipykernel_3952/4130451171.py:136: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_list = pd.read_html(str(table))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing build combinations... (this may take a while if there are many rows)\n",
      "Data saved to mario_kart_stats.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "#########################\n",
    "# Utility functions\n",
    "#########################\n",
    "def flatten_multiindex_columns(df):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with a MultiIndex for columns (possibly 3 levels, e.g.):\n",
    "      (Table Title, Group, Detail)\n",
    "    this function will:\n",
    "      1. If the first level is identical across all columns (e.g. \"Drivers (DV)\"),\n",
    "         drop that level.\n",
    "      2. For the remaining tuple (usually 2-level), if both parts are identical,\n",
    "         return just one part; otherwise, join them with \" - \".\n",
    "    \"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        first_level = df.columns.get_level_values(0)\n",
    "        if len(set(first_level)) == 1:\n",
    "            new_cols = []\n",
    "            for col in df.columns:\n",
    "                sub_tuple = col[1:]\n",
    "                parts = [str(x).strip() for x in sub_tuple if x and not str(x).lower().startswith(\"unnamed\")]\n",
    "                if not parts:\n",
    "                    new_cols.append(\"\")\n",
    "                elif len(parts) == 1:\n",
    "                    new_cols.append(parts[0])\n",
    "                else:\n",
    "                    if parts[0] == parts[1]:\n",
    "                        new_cols.append(parts[0])\n",
    "                    else:\n",
    "                        new_cols.append(\" - \".join(parts))\n",
    "            df.columns = new_cols\n",
    "        else:\n",
    "            new_cols = []\n",
    "            for col in df.columns:\n",
    "                parts = [str(x).strip() for x in col if x and not str(x).lower().startswith(\"unnamed\")]\n",
    "                new_cols.append(\" - \".join(parts))\n",
    "            df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "def replace_img_with_alt(table):\n",
    "    \"\"\"\n",
    "    In the given BeautifulSoup table element, find all <td> and <th> cells.\n",
    "    If a cell contains one or more <img> tags, replace the cell’s contents with\n",
    "    a comma-separated string of the images’ alt attribute values.\n",
    "    \"\"\"\n",
    "    for cell in table.find_all([\"td\", \"th\"]):\n",
    "        imgs = cell.find_all(\"img\")\n",
    "        if imgs:\n",
    "            alt_texts = [img.get(\"alt\", \"\").strip() for img in imgs if img.get(\"alt\")]\n",
    "            if alt_texts:\n",
    "                cell.clear()\n",
    "                cell.append(\", \".join(alt_texts))\n",
    "    return table\n",
    "\n",
    "def remove_footer(table):\n",
    "    \"\"\"\n",
    "    Remove any <tfoot> element from the BeautifulSoup table.\n",
    "    \"\"\"\n",
    "    for t in table.find_all(\"tfoot\"):\n",
    "        t.extract()\n",
    "    return table\n",
    "\n",
    "def drop_footer_row(df):\n",
    "    \"\"\"\n",
    "    If the last row in the DataFrame contains footer text (like \"Unused statistic\")\n",
    "    in every cell, drop that row.\n",
    "    \"\"\"\n",
    "    if not df.empty:\n",
    "        last_row = df.iloc[-1]\n",
    "        if all(\"Unused statistic\" in str(val) for val in last_row):\n",
    "            df = df.iloc[:-1]\n",
    "    return df\n",
    "\n",
    "def separate_numeric_and_nonnumeric(df, identifier):\n",
    "    \"\"\"\n",
    "    For the given DataFrame, separate columns (other than the identifier column)\n",
    "    into numeric and non-numeric.\n",
    "    \n",
    "    Returns two dictionaries mapping column names to Series.\n",
    "      - If pd.to_numeric() converts all values in a column to NaN, it is treated as non-numeric.\n",
    "    \"\"\"\n",
    "    numeric_cols = {}\n",
    "    nonnumeric_cols = {}\n",
    "    for col in df.columns:\n",
    "        if col == identifier:\n",
    "            continue\n",
    "        converted = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        # If no value could be converted, treat the column as non-numeric.\n",
    "        if converted.notna().sum() == 0:\n",
    "            nonnumeric_cols[col] = df[col]\n",
    "        else:\n",
    "            # Use the converted column; fill NaN with 0.\n",
    "            numeric_cols[col] = converted.fillna(0)\n",
    "    return numeric_cols, nonnumeric_cols\n",
    "\n",
    "#########################\n",
    "# Table Extraction\n",
    "#########################\n",
    "def extract_tables(url, table_labels):\n",
    "    \"\"\"\n",
    "    Fetches the page at `url`, replaces image tags with alt text, removes any table footer,\n",
    "    and then extracts tables whose title (a <th> with colspan in the <thead>)\n",
    "    contains one of the strings in `table_labels`.\n",
    "    \n",
    "    For tables with at least 3 header rows (the first being the table title),\n",
    "    we use pd.read_html with header=[0,1,2] so that the columns come in as a MultiIndex.\n",
    "    We then flatten the columns.\n",
    "    \n",
    "    Returns a dictionary mapping each label to its corresponding DataFrame.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    tables_dict = {}\n",
    "    \n",
    "    for table in soup.find_all(\"table\", class_=\"sortable\"):\n",
    "        title_th = table.find(\"th\", colspan=True)\n",
    "        if title_th:\n",
    "            title_text = title_th.get_text(strip=True)\n",
    "            for label in table_labels:\n",
    "                if label in title_text:\n",
    "                    table = remove_footer(table)\n",
    "                    table = replace_img_with_alt(table)\n",
    "                    \n",
    "                    thead = table.find(\"thead\")\n",
    "                    header_rows = thead.find_all(\"tr\") if thead else []\n",
    "                    if len(header_rows) >= 3:\n",
    "                        df_list = pd.read_html(str(table), header=[0, 1, 2])\n",
    "                    elif len(header_rows) == 2:\n",
    "                        df_list = pd.read_html(str(table), header=[0, 1])\n",
    "                    else:\n",
    "                        df_list = pd.read_html(str(table))\n",
    "                    \n",
    "                    if df_list:\n",
    "                        df = df_list[0]\n",
    "                        df = flatten_multiindex_columns(df)\n",
    "                        df = drop_footer_row(df)\n",
    "                        tables_dict[label] = df\n",
    "    return tables_dict\n",
    "\n",
    "#########################\n",
    "# Build Table Computation\n",
    "#########################\n",
    "def compute_build_table(driver_df, body_df, tire_df, glider_df):\n",
    "    \"\"\"\n",
    "    Computes a new DataFrame containing every possible build – one row from each component table –\n",
    "    and sums the numeric stat values across the four parts.\n",
    "    \n",
    "    For non-numeric stat columns (e.g. \"Size\" or \"Vehicle Type\"), which are assumed to appear in only one table,\n",
    "    the value is carried over from that table.\n",
    "    \n",
    "    Identification:\n",
    "      - For drivers, the identifier is the \"Character\" column.\n",
    "      - For bodies, tires, and gliders, the identifier is taken from the first column.\n",
    "    \"\"\"\n",
    "    # Identify the component IDs.\n",
    "    driver_id = driver_df[\"Character\"]\n",
    "    body_id   = body_df.iloc[:, 0]\n",
    "    tire_id   = tire_df.iloc[:, 0]\n",
    "    glider_id = glider_df.iloc[:, 0]\n",
    "    \n",
    "    # Separate each table's stat columns into numeric and non-numeric.\n",
    "    driver_numeric, driver_nonnum = separate_numeric_and_nonnumeric(driver_df, \"Character\")\n",
    "    body_numeric,   body_nonnum   = separate_numeric_and_nonnumeric(body_df, body_df.columns[0])\n",
    "    tire_numeric,   tire_nonnum   = separate_numeric_and_nonnumeric(tire_df, tire_df.columns[0])\n",
    "    glider_numeric, glider_nonnum = separate_numeric_and_nonnumeric(glider_df, glider_df.columns[0])\n",
    "    \n",
    "    # Union of numeric stat column names across tables.\n",
    "    numeric_stats = set(driver_numeric.keys()) | set(body_numeric.keys()) | set(tire_numeric.keys()) | set(glider_numeric.keys())\n",
    "    numeric_stats = sorted(list(numeric_stats))\n",
    "    \n",
    "    # For non-numeric stats, assume that they appear only in one table.\n",
    "    nonnumeric_stats = {}\n",
    "    for col, series in driver_nonnum.items():\n",
    "        nonnumeric_stats[col] = (\"Driver\", series)\n",
    "    for col, series in body_nonnum.items():\n",
    "        nonnumeric_stats[col] = (\"Body\", series)\n",
    "    for col, series in tire_nonnum.items():\n",
    "        nonnumeric_stats[col] = (\"Tire\", series)\n",
    "    for col, series in glider_nonnum.items():\n",
    "        nonnumeric_stats[col] = (\"Glider\", series)\n",
    "    \n",
    "    build_rows = []\n",
    "    # Iterate over every combination (Cartesian product).\n",
    "    for d_idx, b_idx, t_idx, g_idx in itertools.product(driver_df.index, body_df.index, tire_df.index, glider_df.index):\n",
    "        row = {}\n",
    "        row[\"Driver\"] = driver_id.loc[d_idx]\n",
    "        row[\"Body\"]   = body_id.loc[b_idx]\n",
    "        row[\"Tire\"]   = tire_id.loc[t_idx]\n",
    "        row[\"Glider\"] = glider_id.loc[g_idx]\n",
    "        \n",
    "        # For each numeric stat, sum its values from the four tables (using 0 if absent).\n",
    "        for stat in numeric_stats:\n",
    "            total = 0\n",
    "            if stat in driver_numeric:\n",
    "                total += driver_numeric[stat].loc[d_idx]\n",
    "            if stat in body_numeric:\n",
    "                total += body_numeric[stat].loc[b_idx]\n",
    "            if stat in tire_numeric:\n",
    "                total += tire_numeric[stat].loc[t_idx]\n",
    "            if stat in glider_numeric:\n",
    "                total += glider_numeric[stat].loc[g_idx]\n",
    "            row[stat] = total\n",
    "        \n",
    "        # For each non-numeric stat, simply use the value from the table that contains it.\n",
    "        for col, (source, series) in nonnumeric_stats.items():\n",
    "            if source == \"Driver\":\n",
    "                row[col] = series.loc[d_idx]\n",
    "            elif source == \"Body\":\n",
    "                row[col] = series.loc[b_idx]\n",
    "            elif source == \"Tire\":\n",
    "                row[col] = series.loc[t_idx]\n",
    "            elif source == \"Glider\":\n",
    "                row[col] = series.loc[g_idx]\n",
    "        \n",
    "        build_rows.append(row)\n",
    "    build_df = pd.DataFrame(build_rows)\n",
    "    return build_df\n",
    "\n",
    "#########################\n",
    "# Save to Excel\n",
    "#########################\n",
    "def save_tables_to_excel(tables_dict, output_file):\n",
    "    \"\"\"\n",
    "    Saves each DataFrame in `tables_dict` to a separate sheet in an Excel workbook.\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for label, df in tables_dict.items():\n",
    "            sheet_name = label if len(label) <= 31 else label[:31]\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "#########################\n",
    "# Main Execution\n",
    "#########################\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.mariowiki.com/Mario_Kart_8_Deluxe_in-game_statistics\"\n",
    "    table_labels = [\"Drivers (DV)\", \"Bodies (BD)\", \"Tires (TR)\", \"Gliders (WG)\"]\n",
    "    \n",
    "    tables = extract_tables(url, table_labels)\n",
    "    if not tables:\n",
    "        print(\"No matching tables found on the page.\")\n",
    "    else:\n",
    "        try:\n",
    "            driver_df = tables[\"Drivers (DV)\"]\n",
    "            body_df   = tables[\"Bodies (BD)\"]\n",
    "            tire_df   = tables[\"Tires (TR)\"]\n",
    "            glider_df = tables[\"Gliders (WG)\"]\n",
    "            \n",
    "            print(\"Computing build combinations... (this may take a while if there are many rows)\")\n",
    "            build_df = compute_build_table(driver_df, body_df, tire_df, glider_df)\n",
    "            tables[\"Builds\"] = build_df\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing one of the required tables: {e}\")\n",
    "        \n",
    "        save_tables_to_excel(tables, \"mario_kart_stats.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
